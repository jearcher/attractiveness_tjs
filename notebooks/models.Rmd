---
title: "All About Attraction: Does Working at Trader Joe's Increase Your Attractiveness?"
author: "Josh Archer, Hannah Choi, Josh Lin, Pauline Yue"
output: github_document
---

```{r, include=FALSE}
library(data.table)
library(dplyr)
library(lmtest)
library(sandwich)
library(stargazer)
library(pwr)
```

## Abstract
This study seeks to investigate how working at Trader Joe's affects one's attractiveness. Our null hypothesis was that working at Trader Joe's does not influence an individual's attractiveness, and our alternative hypothesis is that it does. For this research, we implemented a survey design in which we asked participants to choose between two photos of individuals, for a total of 14 pairs. We obtained 247 completed responses, and we conducted several linear regression models on our data. In the end, we were unable to reject the null hypothesis, as we did not find our results to be statistically significant. Nonetheless, we feel that our study begs further research to better understand how people define attraction.  

 
## Background

Over the years, Trader Joe's has become more than just a place to get groceries, but rather an experience in itself. From tropical island themed interior and uniforms for their employees, to unique products only found at Trader Joe's, the brand has a competitive edge in the grocery industry. The culture around the store has allowed it to develop a cult following of customers who rave about their products. More recently, there has been increasing attention towards the store's employees and the general opinion that Trader Joe's workers are more attractive than the average individual.     

Based on this observed social phenomenon, we conducted an experiment to test this hypothesis. We are interested if a person's place of work really has an effect on their attractiveness, because we recognize that part of an individual's image is defined (for better or worse) by their professional role.   

## Research Question & Hypothesis
	
Our research question is: Does working at Trader Joe's make you more attractive? We measured and compared 'attractiveness' of the subjects by counting the number of times a photo was chosen in treatment (with a logo) versus the number of times the photo was chosen in control (without a logo).  

Our *null hypothesis* is that working at Trader Joe's has no effect on how attractive a person is, and our *alternative hypothesis* is that working at Trader Joe's has an effect on how attractive a person is. Based on our own experiences at Trader Joe's we expect there will be a positive impact of treatment on attractiveness. We also had an additional sub-question in which we were interested in studying the effect of smiling on attraction. Our null hypothesis for this sub-question is that smiling has no effect on attraction, and our alternative hypothesis is that smiling does have an effect.  

## Experiment/Research Design

### Study Design

For our study, we implemented a survey in which participants swipe through various pairs of photos and choose the individual they are more attracted to. We obtained photos from our personal circle of friends, and we attempted to maintain a wide array of individuals in our photo sample. In total, we received 30 photos from 15 female-identifying folks, and 36 photos from 19 male-identifying folks.  

#### Pilot Study
We designed a pilot study (n=50) similar to our experimental survey that featured the same swipe design. We distributed the pilot study via Amazon Mechanical Turk first to determine how long it would take participants to finish the survey and what feedback they might give in response to our free response question to help us improve our final iteration. We read through the free responses to determine which choices we would include in the main study questions about physical and personality traits.  

#### Main Study
We then posted our final survey through Amazon Mturk. In the final survey, all participants (n = 247) were prompted to choose who they found more attractive between a total of 14 pairs of individuals (14 male and 14 female) in a single-blind study. Two multiple choice questions appear after the selection asking what physical trait (smile, body type, hair, or eyes) and personality trait (kind, fun, adventurous, hardworking, or trustworthy) motivated their selection the most. We chose these answer choices based on the responses of the open-ended version of those questions in the pilot survey. At the end of the survey we asked the same 2 questions with regards to an ideal partner in order to see if that criteria stayed the same throughout the survey. In total, the questions across all surveys remained the same with the variation being the pairs and type of image used for each subject.    

### Treatment

The baseline for all photos was an individual wearing a monochrome shirt visible from the waist-up. The treatment in this study is the placement of a logo on a subject's t-shirt- the original photo altered with either a Trader Joe's and Nike logo prominently placed. This design created 6 iterations of an individual (smiling with no logo, smiling with Trader Joe's, smiling with Nike, non-smiling with no logo, non-smiling with Trader Joe's, and non-smiling with Nike; see Appendix for example images). Although the main goal of our experiment was to see if the presence of a Trader Joe's logo would make an individual more attractive, we also included the Nike logo to see if there was an overall effect of a logo on one's attractiveness. It also served as a means to maintain the single-blind nature of our study so that respondents would not infer that we were testing for the effect of a Trader Joe's affiliation on attractiveness. Furthermore, we wanted to see if smiling had an effect on attraction, and thus added smiling as a feature and potential covariate.   

### Randomization engineering

We created 4 sets of control and treatment survey versions-control A, treatment A, control B, treatment B, control C, treatment C, control D, and treatment D. Within each set of treatment and control groups the same pairs and baseline photos were utilized, and only the treatment groups saw the introduction of a logo. The pairs and what type of logo (none, Trader Joe's, or Nike) an individual would have were randomly generated. We implemented the randomizer function within Qualtrics to ensure that the question blocks with photographs would randomly present evenly across the survey distribution. There were 30-32 respondents in each survey group (see consort document below). We also used tools in Qualtrics to enable each of the question choices to appear in a random order, to minimize the possible human error of participants simply just clicking through the survey. Randomization of the pairings was crucial to ensure that an individual with a baseline attractiveness objectively higher than others did not overshadow the effect of the logos.   

### Experimental materials (e.g. treatment materials)
The subjects of our study were 19 males and 15 females who volunteered to have their photos taken to be put in our surveys. Their photos were taken from the waist up, in a plain, solid color t-shirt, with variations of smiling or not smiling. Their t-shirts were kept plain so that we could either use that photo as a control, or photoshop a Trader Joe's or Nike logo onto them as treatment. The outcome we measured was the total number of times each photo was chosen.   

Our study participants were Amazon Mechanical Turk workers who were located in the United States, had a high approval rating (> 90%), and a high quantity of approvals (> 50). We were able to receive a total of 247 completed responses to our survey. We were unable to view the incomplete responses through Qualtrics and did not include them in our analysis.   


## Modeling Choices
For our analysis, we decided to use linear regression to test our hypotheses. We were interested in regressing the total number of times a picture was chosen on whether or not the photo contained a Trader Joe's logo. At first, we built a linear regression model that compared photos that had a Trader Joe's logo to all other photos-both photos that were blank in both control and treatment and photos that contained a Nike logo.   

However, this is an unbalanced comparison since the photos with Trader Joe's logos were compared to all photos. Thus, we decided to compare the photos in treatment with a TJs logo to the matching subset of photos in control. There were 42 photos in treatment with a Trader Joe's logo which we matched with 42 of the same photos in control without the logo. This resulted in a more accurate yet underpowered estimation of the linear model.   

In order to avoid confusing a "Trader Joe's Logo" effect with a general logo effect, we did a similar comparison for Nike photos. We matched the 39 photos in treatment with a Nike logo to their 39 counterparts in control. We did not run this model to investigate a Nike logo effect, but instead referenced this model to better understand the Trader Joe's Logo Effect. For example, if there was a positive treatment effect for Trader joe's treatment and Nike treatment, we might think there is a general logo effect that is not specific to a Trader Joe's logo. However, as we will explore in the results section, the Trader Joe's and Nike logos have opposite estimated effects on outcomes.  

```{r data, echo=FALSE}
data <- fread("../data/processed/analysis_table.csv")

data[, treat_ind := ifelse(treat=='t',1,0)]

data[, treat_with_logo := ifelse((logo != 'none' & treat == 't'),1 ,0)]

data[, tjs_logo := ifelse(test = grepl(pattern = "tjs", data[, logo]),
                                              yes = 1, no = 0)]

data[, nike_logo := ifelse(test = grepl(pattern = "nike", data[, logo]),
                                              yes = 1, no = 0)]

data[, no_logo := ifelse(test = grepl(pattern = "none", data[, logo]),
                                              yes = 1, no = 0)]
data[, survey_block := gsub("^.*_", "", data$photo_block)]
data[, smile_ind := ifelse(data[,smile=='smile'], 1, 0)]

#names(data)

#View(data)
```

## Results
```{r histograms, message=FALSE, warning=FALSE}
hist(data[data$tjs_logo==1]$total_counts, xlab= "Total Times Chosen",
     main = "Distribution of Counts for Trader Joe's Photos")
hist(data[data$treat_ind==0]$total_counts, xlab= "Total Times Chosen",
     main = "Distribution of Counts for Blank Photos")
hist(data[data$nike_logo==1]$total_counts, xlab= "Total Times Chosen",
     main = "Distribution of Counts for Nike Photos")
hist(data[data$smile_ind==1]$total_counts, xlab= "Total Times Chosen",
     main = "Distribution of Counts for Smiling Photos")
hist(data[data$smile_ind==0]$total_counts, xlab= "Total Times Chosen",
     main = "Distribution of Counts for Non-Smiling Photos")

```

```{r initialize stargazer, include= False}
robust_se <- function(mod, type = 'HC3') { sqrt(diag(vcovHC(mod, type)))}
```

```{r baseline}
model_1 <- data[, lm(total_counts ~ tjs_logo)]
coeftest(model_1, vcovHC(model_1))
```

```{r baseline + blocks}
model_2 <- data[, lm(total_counts ~ tjs_logo + survey_block)]
coeftest(model_2, vcovHC(model_2))
anova(model_1, model_2, test= 'F')
```
Although the F-test p-value is almost 1, looking at this second baseline model, we can see that our randomization was successful, since we did not see within-survey group effects. In other words, our treatment fulfilled the exclusion principle. (*add more here later*)


```{r without nike}
model_3 <- data[nike_logo ==  0, lm(total_counts ~ tjs_logo)]
coeftest(model_3, vcovHC(model_3))
```


```{r smile model}
model_4 <- data[, lm(total_counts ~ tjs_logo + smile_ind)]
coeftest(model_4, vcovHC(model_4))
anova(model_1, model_4, test = 'F')
```


```{r}
stargazer(model_1, model_2, model_3, model_4, type = 'text', 
          se = list(robust_se(model_1),robust_se(model_2), robust_se(model_3), robust_se(model_4)),
          column.labels = c('Model 1', 'Model 2', 'Model 3', 'Model 4'),
          dep.var.labels = c('Total Number of Times Chosen'),
          covariate.labels = c("Trader Joe's Logo", 'Survey Block B', 
                               'Survey Block C', 'Survey Block D',
                              'Smile', 'Baseline'),
          title = "Table 1: Baseline Models")
```

```{r clean for tj vs control}
# Remove nike logo photos and look for just tjs photos
interim <- data[logo != "nike"]
tjs_only <- data[logo == "tjs"]

# Create a join_id to combine tables later
photo_name_split <- read.table(text = interim[ , photo_block], sep = "_", as.is = TRUE, fill = TRUE)
interim[, join_id := paste(photo_name_split$V1, photo_name_split$V2, photo_name_split$V3, photo_name_split$V6, photo_name_split$V7, sep="_")]
interim[, gender := photo_name_split$V2]

## Subset needed columns and match control photos to tjs photos (not including photos that were blank in both control and treatment)
tjs_only <- interim[logo=="tjs"]
tjs_only <- tjs_only[ , c("photo_block", "join_id", "treat_ind", "survey_block", "total_counts", "smile_ind", "gender")]
rows_to_keep <- tjs_only[, join_id]
none_c_only <- interim[logo=="none" & treat_ind<1]
none_c_only <- none_c_only[ , c("photo_block", "join_id", "treat_ind", "survey_block", "total_counts", "smile_ind", "gender")]
none_c_matched <- subset(none_c_only, join_id %in% rows_to_keep)

# none_c_rows <- none_c_matched[, join_id]
# tjs_issue <- subset(tjs_only, !(join_id %in% none_c_rows))

# View(none_c_matched)
tjs_vs_control <- rbind(tjs_only, none_c_matched)
#View(tjs_vs_control)
```

```{r new baseline for just tjs}
#42 blanks and 42 with tj's
model_5 <- tjs_vs_control[, lm(total_counts ~ treat_ind)]
coeftest(model_5, vcovHC(model_5))
```

```{r tjs only + smile model}
model_6 <- tjs_vs_control[, lm(total_counts ~ treat_ind + smile_ind + treat_ind*smile_ind)]
coeftest(model_6, vcovHC(model_6))
anova(model_5, model_6, test = 'F')
```

```{r tjs only + gender model}
model_7 <- tjs_vs_control[, lm(total_counts ~ treat_ind + gender + treat_ind*gender)]
coeftest(model_7, vcovHC(model_7))
anova(model_5, model_7, test = 'F')
```
Here, we observe that the estimated effect of being shown a male subject in the photo and the interaction term between having a logo and the male gender were positive. It's likely that the respondents overall felt that certain male photo subjects were more attractive on average compared to other photo subjects within the survey sets, and that certain male photo subjects had a larger boost in their selection rates due to the Trader Joe's logo compared to the effect the logo had for females.


```{r tjs saturated model}
model_gen_smile <- tjs_vs_control[, lm(total_counts ~ treat_ind + smile_ind + treat_ind*smile_ind
                                       + gender + treat_ind*gender + smile_ind*gender)]
coeftest(model_gen_smile, vcovHC(model_gen_smile))
anova(model_5, model_gen_smile, test = 'F')
```

```{r tjs stargazer}
stargazer(model_5, model_6, model_7, model_gen_smile, type = 'text', 
          se = list(robust_se(model_5), robust_se(model_6), robust_se(model_7), 
                    robust_se(model_gen_smile)),
          column.labels = c('Model 5', 'Model 6', 'Model 7', 'Saturated Model'),
          dep.var.labels = c('Total Number of Times Chosen'),
          covariate.labels = c("Contains Logo", 'Smile', 
                               'Contains Logo*Smile', 'Male Photo Subject', "Contains Logo*Male",
                              'Smile*Male', 'Baseline'),
          title = "Table 2: Trader Joe's Only Models")
```


```{r clean for nike vs control}
interim <- copy(data)
photo_name_split <- read.table(text = interim[ , photo_block], sep = "_", as.is = TRUE, fill = TRUE)
interim[, join_id := paste(photo_name_split$V1, photo_name_split$V2, photo_name_split$V3, photo_name_split$V6, photo_name_split$V7, sep="_")]
interim[, gender := photo_name_split$V2]
# View(interim)

nike_only <- interim[logo=="nike"]
nike_only <- nike_only[ , c("photo_block", "join_id", "treat_ind", "survey_block", "total_counts", "smile_ind", "gender")]
rows_to_keep_nike <- nike_only[, join_id]
none_c_matched <- subset(none_c_only, join_id %in% rows_to_keep_nike)
# none_c_rows <- none_c_matched[, join_id]
# tjs_issue <- subset(tjs_only, !(join_id %in% none_c_rows))
# View(none_c_matched)
nike_vs_control <- rbind(nike_only, none_c_matched) # only has 39 blanks and 39 nike logo photos
```

```{r nike only baseline}
model_8 <- nike_vs_control[, lm(total_counts ~ treat_ind)]
coeftest(model_8, vcovHC(model_8))
```
To ensure that the effect we observed for our above Trader Joe's baseline model (Model 5) is not due to simply adding a logo to a photo, we included photos that had a Nike logo as a robustness check.  While the number of Nike logo pairs is smaller (n=39), the overall ratio is almost the same, and because of the similar proportion of photos pairs, we can infer that the estimated effect we saw in the Trader Joe's baseline model is unique to the Trader Joe's logo as they two slope coefficients are vastly different.

```{r nike only + smile}
#interaction term not included because of perfect collinearity (potentially a product of randomization)
model_9 <- nike_vs_control[, lm(total_counts ~ treat_ind + smile_ind)]
coeftest(model_9, vcovHC(model_9))
anova(model_8, model_9, test = 'F')
```

```{r nike only + gender}
model_10 <- nike_vs_control[, lm(total_counts ~ treat_ind + gender + treat_ind*gender)]
coeftest(model_10, vcovHC(model_10))
anova(model_8, model_10, test = 'F')
```

```{r nike saturated model}
model_nike_gen_smile <- nike_vs_control[, lm(total_counts ~ treat_ind + smile_ind
                                       + gender + treat_ind*gender)]
coeftest(model_nike_gen_smile, vcovHC(model_nike_gen_smile))
anova(model_8, model_nike_gen_smile, test = 'F')
```

```{r nike stargazer}
stargazer(model_8, model_9, model_10, model_nike_gen_smile, type = 'text', 
          se = list(robust_se(model_8), robust_se(model_9), robust_se(model_10), 
                    robust_se(model_nike_gen_smile)),
          column.labels = c('Model 8', 'Model 9', 'Model 10', 'Saturated Model'),
          dep.var.labels = c('Total Number of Times Chosen'),
          covariate.labels = c("Contains Logo", 'Smile', 'Male Photo Subject',
                               "Contains Logo*Male", 'Baseline'),
          title = "Table 3: Nike Only Models")
```

### Power Calculation

```{r power calculation}
#Power calculation using model_6
summary(model_5)
effect_size <- 0.02517/(1-0.02517) #use multiple R-squared value from model 6 summary
pwr.f2.test(u = 1, v = 82, f2 = effect_size) #u and v come from DF from summary
```
To determine how much statistical power our final model (Model 5) had, based on our model parameters, we found that our model had about 30.73% statistical power. This means that our model only had 30.73% chance of reporting a true positive result. Although the reported statistical power is quite low, we feel that this level of power is understandable given our small data size and the fact we were dealing with data related to how humans think.    

First, when we only focused on photos that were blank in control and contained a Trader Joe's logo in treatment, we only had 42 total unique photo subjects. Therefore, we were comparing across 42 pairs, which is a fairly small dataset. Second, when dealing with sociology- and psychology-type questions like attraction, given the limitations of our experimental design, we cannot fully capture how humans think using the variables we had operationalized. Therefore, we argue that it is reasonable that our statistical power is quite small.

## Limitations and Next Steps 

Moving forward with our study, we indeed realize there is much more we can do to iterate upon our experiment. If we were to rerun this experiment, we first want to increase our sample size. While we were able to work within our budget and time frame and obtain 275 responses, our sample is still not entirely representative of the entire population. Looking at the demographics, we do not have a fair number of respondents from older and younger age groups, since our responses mainly came from middle aged individuals. Aside from increasing the sample size, we would also want to further randomize the order of the photos and incorporate a mechanism for selected photos to reappear within the question bank, as having respondents select through the photos multiple times would allow us to hone in more closely at the true treatment effect. We would also include more subjects for our photos so that our photos better represent the population as well, since all our subjects came from our circle of friends and, thus, primarily came from a younger age group.

Moving forward with this study, we would also like to in

## Conclusion
