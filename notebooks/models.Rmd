---
title: "All About Attraction: Does Working at Trader Joe's Increase Your Attractiveness?"
author: "Josh Archer, Hannah Choi, Josh Lin, Pauline Yue"
output: github_document
---

```{r, include=FALSE}
library(data.table)
library(dplyr)
library(lmtest)
library(sandwich)
library(stargazer)
library(pwr)
```

## Abstract

 
## Background

Over the years, Trader Joe's has become more than just a place to get groceries, but rather an experience in itself. From tropical island themed interior and uniforms for their employees, to unique products only found at Trader Joe's, the brand has a competitive edge in the grocery industry. The culture around the store has allowed it to develop a cult following of customers who rave about their products. More recently, there has been increasing attention towards the store's employees and the general opinion that Trader Joe's workers are more attractive than the average individual. Based on this observed social phenomenon, we conducted an experiment to test this hypothesis. 

## Research Question & Hypothesis
	
Does working at Trader Joe's make you more attractive? 
Null Hypothesis: Working at Trader Joe's has no affect on attraction
Alternative Hypothesis: Working at Trader Joe's has an affect on attraction

## Experiment/Research Design

### Study Design

For our study, we implemented a swipe-style survey similar to modern-day dating apps like Tinder, in which participants swipe through various photos and choose the individual they are more attracted to. We obtained photos from our personal circle of friends, and we attempted to maintain a wide array of individuals in our photo sample. In total, we received 30 photos from 15 female-identifying folks, and 36 photos from 19 male-identifying folks. We also designed a pilot study similar to our experimental survey that featured the same swipe design, but on a smaller scale. We distributed the pilot study first to determine how long it would take participants to finish the survey and what feedback they might give in response to our free response question to help us improve our final iteration. We then posted our final survey through Amazon Mturk.

In the survey, all participants (n = 247) were prompted to choose who they found more attractive between a total of 14 pairs of individuals (14 male and 14 female) in a single-blind study. Two multiple choice questions appear after the selection asking what physical trait (smile, body type, hair, or eyes) and personality trait (kind, fun, adventurous, hardworking, or trustworthy) motivated their selection the most. We chose these answer choices based on the responses of the open-ended version of those questions in the pilot survey (n = 50). At the end of the survey we asked the same 2 questions with regards to an ideal partner in order to see if that criteria stayed the same throughout the survey. In total, the questions across all surveys remained the same with the variation being the pairs and type of image used for each subject. 

### Treatment

The baseline for all photos was an individual wearing a monochrome shirt visible from the waist-up. The treatment in this study is the placement of a logo on a subject- the original photo altered with either a Trader Joe's and Nike logo prominently placed. This design created 6 iterations of an individual (smiling with no logo, smiling with Trader Joe's, smiling with Nike, non-smiling with no logo, non-smiling with Trader Joe's, and non-smiling with Nike). Although the main goal of our experiment was to see if the presence of a Trader Joe's logo would make an individual more attractive, we also included the Nike logo to see if there was an overall effect of a logo on one's attractiveness. It also served as a placebo of sorts and a means to maintain the single-blind nature of our study so that respondents would not infer that we were testing for the effect of a Trader Joe's affiliation on attractiveness. Furthermore, we wanted to see if smiling had an effect on attraction, and thus added smiling as a feature and potential covariate. 

### Randomization engineering

We created 4 sets of control and treatment [attraction selection question blocks]-control A, treatment A, control B, treatment B, control C, treatment C, control D, and treatment D. Within each set of treatment and control groups the same pairs and baseline photos were utilized, and only the treatment groups saw the introduction of a logo. The pairs and what type of logo (none, Trader Joe's, or Nike) an individual would have were randomly generated by using Python [insert code?] We implemented the randomizer function within Qualtrics to ensure that the question blocks with photographs would randomly present evenly across the survey distribution. [insert how many people were in each group]. We also used tools in Qualtrics to enable each of the question choices to appear in a random order, to minimize the possible human error of participants simply just clicking through the survey. Randomization the pairings was crucial to ensure that an individual with a baseline attractiveness objectively higher than others did not overshadow the effect of the logos. 

### Experimental materials (e.g. treatment materials)
#### Measurement of variables
The Primary outcome was :
- 0 if the person chosen was not wearing a logo
- 1 if the person was wearing a Trader Joe's logo
- 2 if the person was wearing a Nike logo

## Modeling Choices
(blurb here about choosing to use models)
```{r data, echo=FALSE}
data <- fread("../data/processed/analysis_table.csv")

data[, treat_ind := ifelse(treat=='t',1,0)]

data[, treat_with_logo := ifelse((logo != 'none' & treat == 't'),1 ,0)]

data[, tjs_logo := ifelse(test = grepl(pattern = "tjs", data[, logo]),
                                              yes = 1, no = 0)]

data[, nike_logo := ifelse(test = grepl(pattern = "nike", data[, logo]),
                                              yes = 1, no = 0)]

data[, no_logo := ifelse(test = grepl(pattern = "none", data[, logo]),
                                              yes = 1, no = 0)]
data[, survey_block := gsub("^.*_", "", data$photo_block)]
data[, smile_ind := ifelse(data[,smile=='smile'], 1, 0)]

#names(data)

#View(data)
```

## Results
```{r histograms, message=FALSE, warning=FALSE}
hist(data[data$tjs_logo==1]$total_counts)
hist(data[data$treat_ind==0]$total_counts)
hist(data[data$nike_logo==1]$total_counts)

# Why does this print density, etc text. Maybe split into different chunks? Maybe write it similar to above?
data[smile_ind == 0, hist(total_counts)]
data[smile_ind == 1, hist(total_counts)]
```

```{r initialize stargazer}
robust_se <- function(mod, type = 'HC3') { sqrt(diag(vcovHC(mod, type)))}
```

```{r baseline}
model_1 <- data[, lm(total_counts ~ tjs_logo)]
coeftest(model_1, vcovHC(model_1))
```

```{r baseline + blocks}
model_2 <- data[, lm(total_counts ~ tjs_logo + survey_block)]
coeftest(model_2, vcovHC(model_2))
anova(model_1, model_2, test= 'F')
```
Although the F-test p-value is almost 1, looking at this second baseline model, we can see that our randomization was successful, since we did not see within-survey group effects. In other words, our treatment fulfilled the exclusion principle. (*add more here later*)


```{r without nike}
model_3 <- data[nike_logo ==  0, lm(total_counts ~ tjs_logo)]
coeftest(model_3, vcovHC(model_3))
```


```{r smile model}
model_4 <- data[, lm(total_counts ~ tjs_logo + smile_ind)]
coeftest(model_4, vcovHC(model_4))
anova(model_1, model_4, test = 'F')
```


```{r}
stargazer(model_1, model_2, model_3, model_4, type = 'text', 
          se = list(robust_se(model_1),robust_se(model_2), robust_se(model_3), robust_se(model_4)),
          column.labels = c('Model 1', 'Model 2', 'Model 3', 'Model 4'),
          dep.var.labels = c('Total Number of Times Chosen'),
          covariate.labels = c("Trader Joe's Logo", 'Survey Block B', 
                               'Survey Block C', 'Survey Block D',
                              'Smile', 'Baseline'),
          title = "Table 1: Baseline Models")
```

```{r clean for tj vs control}
# Remove nike logo photos and look for just tjs photos
interim <- data[logo != "nike"]
tjs_only <- data[logo == "tjs"]

# Create a join_id to combine tables later
photo_name_split <- read.table(text = interim[ , photo_block], sep = "_", as.is = TRUE, fill = TRUE)
interim[, join_id := paste(photo_name_split$V1, photo_name_split$V2, photo_name_split$V3, photo_name_split$V6, photo_name_split$V7, sep="_")]
interim[, gender := photo_name_split$V2]

## Subset needed columns and match control photos to tjs photos (not including photos that were blank in both control and treatment)
tjs_only <- interim[logo=="tjs"]
tjs_only <- tjs_only[ , c("photo_block", "join_id", "treat_ind", "survey_block", "total_counts", "smile_ind", "gender")]
rows_to_keep <- tjs_only[, join_id]
none_c_only <- interim[logo=="none" & treat_ind<1]
none_c_only <- none_c_only[ , c("photo_block", "join_id", "treat_ind", "survey_block", "total_counts", "smile_ind", "gender")]
none_c_matched <- subset(none_c_only, join_id %in% rows_to_keep)

# none_c_rows <- none_c_matched[, join_id]
# tjs_issue <- subset(tjs_only, !(join_id %in% none_c_rows))

# View(none_c_matched)
tjs_vs_control <- rbind(tjs_only, none_c_matched)
#View(tjs_vs_control)
```

```{r new baseline for just tjs}
#42 blanks and 42 with tj's
model_5 <- tjs_vs_control[, lm(total_counts ~ treat_ind)]
coeftest(model_5, vcovHC(model_5))
```

```{r tjs only + smile model}
model_6 <- tjs_vs_control[, lm(total_counts ~ treat_ind + smile_ind + treat_ind*smile_ind)]
coeftest(model_6, vcovHC(model_6))
anova(model_5, model_6, test = 'F')
```

```{r tjs only + gender model}
model_7 <- tjs_vs_control[, lm(total_counts ~ treat_ind + gender + treat_ind*gender)]
coeftest(model_7, vcovHC(model_7))
anova(model_5, model_7, test = 'F')
```

```{r tjs saturated model}
model_gen_smile <- tjs_vs_control[, lm(total_counts ~ treat_ind + smile_ind + treat_ind*smile_ind
                                       + gender + treat_ind*gender + smile_ind*gender)]
coeftest(model_gen_smile, vcovHC(model_gen_smile))
anova(model_5, model_gen_smile, test = 'F')
```

```{r tjs stargazer}
stargazer(model_5, model_6, model_7, model_gen_smile, type = 'text', 
          se = list(robust_se(model_5), robust_se(model_6), robust_se(model_7), 
                    robust_se(model_gen_smile)),
          column.labels = c('Model 5', 'Model 6', 'Model 7', 'Saturated Model'),
          dep.var.labels = c('Total Number of Times Chosen'),
          covariate.labels = c("Contains Logo", 'Smile', 
                               'Contains Logo*Smile', 'Male Photo Subject', "Contains Logo*Male",
                              'Smile*Male', 'Baseline'),
          title = "Table 2: Trader Joe's Only Models")
```


```{r clean for nike vs control}
interim <- copy(data)
photo_name_split <- read.table(text = interim[ , photo_block], sep = "_", as.is = TRUE, fill = TRUE)
interim[, join_id := paste(photo_name_split$V1, photo_name_split$V2, photo_name_split$V3, photo_name_split$V6, photo_name_split$V7, sep="_")]
interim[, gender := photo_name_split$V2]
# View(interim)

nike_only <- interim[logo=="nike"]
nike_only <- nike_only[ , c("photo_block", "join_id", "treat_ind", "survey_block", "total_counts", "smile_ind", "gender")]
rows_to_keep_nike <- nike_only[, join_id]
none_c_matched <- subset(none_c_only, join_id %in% rows_to_keep_nike)
# none_c_rows <- none_c_matched[, join_id]
# tjs_issue <- subset(tjs_only, !(join_id %in% none_c_rows))
# View(none_c_matched)
nike_vs_control <- rbind(nike_only, none_c_matched) # only has 39 blanks and 39 nike logo photos
```

```{r nike only baseline}
model_8 <- nike_vs_control[, lm(total_counts ~ treat_ind)]
coeftest(model_8, vcovHC(model_8))
```
To ensure that the effect we observed for our above Trader Joe's baseline model (Model 5) is not due to simply adding a logo to a photo, we included photos that had a Nike logo as a robustness check.  While the number of Nike logo pairs is smaller (n=39), the overall ratio is almost the same, and because of the similar proportion of photos pairs, we can infer that the estimated effect we saw in the Trader Joe's baseline model is unique to the Trader Joe's logo as they two slope coefficients are vastly different.

```{r nike only + smile}
#interaction term not included because of perfect collinearity (potentially a product of randomization)
model_9 <- nike_vs_control[, lm(total_counts ~ treat_ind + smile_ind)]
coeftest(model_9, vcovHC(model_9))
anova(model_8, model_9, test = 'F')
```

```{r nike only + gender}
model_10 <- nike_vs_control[, lm(total_counts ~ treat_ind + gender + treat_ind*gender)]
coeftest(model_10, vcovHC(model_10))
anova(model_8, model_10, test = 'F')
```

```{r nike saturated model}
model_nike_gen_smile <- nike_vs_control[, lm(total_counts ~ treat_ind + smile_ind
                                       + gender + treat_ind*gender)]
coeftest(model_nike_gen_smile, vcovHC(model_nike_gen_smile))
anova(model_8, model_nike_gen_smile, test = 'F')
```

```{r nike stargazer}
stargazer(model_8, model_9, model_10, model_nike_gen_smile, type = 'text', 
          se = list(robust_se(model_8), robust_se(model_9), robust_se(model_10), 
                    robust_se(model_nike_gen_smile)),
          column.labels = c('Model 8', 'Model 9', 'Model 10', 'Saturated Model'),
          dep.var.labels = c('Total Number of Times Chosen'),
          covariate.labels = c("Contains Logo", 'Smile', 'Male Photo Subject',
                               "Contains Logo*Male", 'Baseline'),
          title = "Table 3: Nike Only Models")
```

### Power Calculation

```{r power calculation}
#Power calculation using model_6
summary(model_5)
effect_size <- 0.02517/(1-0.02517) #use multiple R-squared value from model 6 summary
pwr.f2.test(u = 1, v = 82, f2 = effect_size) #u and v come from DF from summary
```
To determine how much statistical power our final model (Model 5) had, based on our model parameters, we found that our model had about 30.73% statistical power. This means that our model only had 30.73% chance of reporting a true positive result. Although the reported statistical power is quite low, we feel that this level of power is understandable given our small data size and the fact we were dealing with data related to how humans think.    

First, when we only focused on photos that were blank in control and contained a Trader Joe's logo in treatment, we only had 42 total unique photo subjects. Therefore, we were comparing across 42 pairs, which is a fairly small dataset. Second, when dealing with sociology- and psychology-type questions like attraction, given the limitations of our experimental design, we cannot fully capture how humans think using the variables we had operationalized. Therefore, we argue that it is reasonable that our statistical power is quite small.

## Limitations and Next Steps 

Moving forward with our study, we indeed realize there is much more we can do to iterate upon our experiment. If we were to rerun this experiment, we first want to increase our sample size. While we were able to work within our budget and time frame and obtain 275 responses, our sample is still not entirely representative of the entire population. Looking at the demographics, we do not have a fair number of respondents from older and younger age groups, since our responses mainly came from middle aged individuals. Aside from increasing the sample size, we would also want to further randomize the order of the photos and incorporate a mechanism for selected photos to reappear within the question bank, as having respondents select through the photos multiple times would allow us to hone in more closely at the true treatment effect. We would also include more subjects for our photos so that our photos better represent the population as well, since all our subjects came from our circle of friends and, thus, primarily came from a younger age group.

Moving forward with this study, we would also like to in


```{r t-tests, echo=FALSE}
#where should this go/should we keep it
#tjs_vs_nike <- data[, t.test(data[tjs_logo == 1, total_counts], data[nike_logo == 1, total_counts])]
#tjs_vs_nike
#tjs_vs_control <- data[, t.test(data[tjs_logo == 1, total_counts], data[tjs_logo == 0, total_counts], paired = T)] #attempt to make these paired later
#tjs_vs_control
#nike_vs_control <- data[, t.test(data[nike_logo == 1, total_counts], data[nike_logo == 0, total_counts])]
#nike_vs_control
#smile_vs_nonsmile <- data[, t.test(data[smile == 'smile', total_counts], data[smile == 'nonsmile', total_counts])]
#smile_vs_nonsmile
```
